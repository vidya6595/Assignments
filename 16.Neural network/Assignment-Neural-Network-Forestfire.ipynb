{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: clang~=5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras~=2.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.18.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.37.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.40.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard~=2.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator~=2.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "Forestfire = pd.read_csv('forestfires.csv')\n",
    "Forestfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variable already present so we can drop month and day\n",
    "\n",
    "Forestfire.drop(['month','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0          small  \n",
       "1           1         0          small  \n",
       "2           1         0          small  \n",
       "3           0         0          small  \n",
       "4           0         0          small  \n",
       "..        ...       ...            ...  \n",
       "512         0         0          large  \n",
       "513         0         0          large  \n",
       "514         0         0          large  \n",
       "515         0         0          small  \n",
       "516         0         0          small  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Forestfire['size_category'] = le.fit_transform(Forestfire['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthfeb  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0              1  \n",
       "1         0              1  \n",
       "2         0              1  \n",
       "3         0              1  \n",
       "4         0              1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Forestfire.drop('size_category',axis=1)\n",
    "y = Forestfire['size_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    1\n",
       "516    1\n",
       "Name: size_category, Length: 517, dtype: int32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((413, 28), (104, 28), (413,), (104,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.20,random_state=15,stratify = y)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(28,input_dim=28,activation='relu'))\n",
    "model.add(Dense(24,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 1s 17ms/step - loss: 0.6948 - accuracy: 0.5326 - val_loss: 0.7081 - val_accuracy: 0.6350\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7210 - val_loss: 0.6798 - val_accuracy: 0.7299\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7391 - val_loss: 0.6692 - val_accuracy: 0.7591\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7428 - val_loss: 0.6665 - val_accuracy: 0.7518\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.5065 - accuracy: 0.7464 - val_loss: 0.6668 - val_accuracy: 0.7810\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7500 - val_loss: 0.6759 - val_accuracy: 0.7883\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7754 - val_loss: 0.6849 - val_accuracy: 0.7956\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.6866 - val_accuracy: 0.7956\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.7935 - val_loss: 0.6904 - val_accuracy: 0.7956\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8080 - val_loss: 0.6996 - val_accuracy: 0.8102\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8152 - val_loss: 0.7050 - val_accuracy: 0.8102\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8188 - val_loss: 0.7164 - val_accuracy: 0.8102\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3749 - accuracy: 0.8333 - val_loss: 0.7214 - val_accuracy: 0.8175\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8333 - val_loss: 0.7256 - val_accuracy: 0.8102\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8406 - val_loss: 0.7384 - val_accuracy: 0.8175\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8623 - val_loss: 0.7441 - val_accuracy: 0.8248\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8659 - val_loss: 0.7642 - val_accuracy: 0.8175\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.3067 - accuracy: 0.8768 - val_loss: 0.7762 - val_accuracy: 0.8175\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8913 - val_loss: 0.7969 - val_accuracy: 0.8248\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8877 - val_loss: 0.7988 - val_accuracy: 0.8321\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.8986 - val_loss: 0.8218 - val_accuracy: 0.8321\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2529 - accuracy: 0.8986 - val_loss: 0.8356 - val_accuracy: 0.8321\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.9058 - val_loss: 0.8443 - val_accuracy: 0.8394\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9130 - val_loss: 0.8701 - val_accuracy: 0.8394\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9167 - val_loss: 0.8859 - val_accuracy: 0.8394\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9384 - val_loss: 0.9059 - val_accuracy: 0.8394\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1912 - accuracy: 0.9420 - val_loss: 0.9158 - val_accuracy: 0.8394\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.9457 - val_loss: 0.9333 - val_accuracy: 0.8394\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9565 - val_loss: 0.9617 - val_accuracy: 0.8394\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9457 - val_loss: 0.9703 - val_accuracy: 0.8394\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9601 - val_loss: 0.9896 - val_accuracy: 0.8394\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1429 - accuracy: 0.9601 - val_loss: 1.0208 - val_accuracy: 0.8394\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9565 - val_loss: 1.0430 - val_accuracy: 0.8394\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9638 - val_loss: 1.0718 - val_accuracy: 0.8394\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9638 - val_loss: 1.0843 - val_accuracy: 0.8394\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1151 - accuracy: 0.9601 - val_loss: 1.0990 - val_accuracy: 0.8321\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9746 - val_loss: 1.1084 - val_accuracy: 0.8248\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9746 - val_loss: 1.1606 - val_accuracy: 0.8394\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9710 - val_loss: 1.1543 - val_accuracy: 0.8321\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9855 - val_loss: 1.1728 - val_accuracy: 0.8321\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9783 - val_loss: 1.2087 - val_accuracy: 0.8394\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9819 - val_loss: 1.2327 - val_accuracy: 0.8321\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9891 - val_loss: 1.2417 - val_accuracy: 0.8248\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9855 - val_loss: 1.2591 - val_accuracy: 0.8248\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9855 - val_loss: 1.2754 - val_accuracy: 0.8321\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9819 - val_loss: 1.3044 - val_accuracy: 0.8321\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9891 - val_loss: 1.3175 - val_accuracy: 0.8394\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9928 - val_loss: 1.3330 - val_accuracy: 0.8394\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9819 - val_loss: 1.3475 - val_accuracy: 0.8394\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.8394\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9819 - val_loss: 1.3877 - val_accuracy: 0.8394\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0494 - accuracy: 0.9964 - val_loss: 1.4150 - val_accuracy: 0.8467\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9855 - val_loss: 1.4063 - val_accuracy: 0.8321\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9891 - val_loss: 1.4427 - val_accuracy: 0.8394\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9928 - val_loss: 1.4510 - val_accuracy: 0.8248\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9928 - val_loss: 1.4739 - val_accuracy: 0.8467\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9928 - val_loss: 1.4816 - val_accuracy: 0.8394\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 1.4990 - val_accuracy: 0.8394\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.5006 - val_accuracy: 0.8321\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.5284 - val_accuracy: 0.8394\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9964 - val_loss: 1.5426 - val_accuracy: 0.8321\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9964 - val_loss: 1.5517 - val_accuracy: 0.8321\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9964 - val_loss: 1.5728 - val_accuracy: 0.8394\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.8394\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.8467\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9964 - val_loss: 1.6290 - val_accuracy: 0.8321\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9964 - val_loss: 1.6491 - val_accuracy: 0.8394\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.8394\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.6795 - val_accuracy: 0.8394\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9964 - val_loss: 1.6823 - val_accuracy: 0.8321\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.8467\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.7186 - val_accuracy: 0.8248\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.7390 - val_accuracy: 0.8540\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.7347 - val_accuracy: 0.8248\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.7633 - val_accuracy: 0.8467\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.7624 - val_accuracy: 0.8321\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.8248\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.7955 - val_accuracy: 0.8394\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 1.8063 - val_accuracy: 0.8467\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8177 - val_accuracy: 0.8248\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.8394\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 1.8394 - val_accuracy: 0.8394\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 1.8713 - val_accuracy: 0.8467\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 1.8522 - val_accuracy: 0.8321\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8783 - val_accuracy: 0.8394\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.8838 - val_accuracy: 0.8394\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.8394\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9071 - val_accuracy: 0.8394\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.8467\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.9260 - val_accuracy: 0.8394\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.9497 - val_accuracy: 0.8540\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.9538 - val_accuracy: 0.8394\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.9698 - val_accuracy: 0.8394\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.9779 - val_accuracy: 0.8467\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.9758 - val_accuracy: 0.8467\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.9969 - val_accuracy: 0.8467\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.8394\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.8321\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.0412 - val_accuracy: 0.8540\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.8467\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0407 - val_accuracy: 0.8321\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0618 - val_accuracy: 0.8467\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0732 - val_accuracy: 0.8394\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0813 - val_accuracy: 0.8394\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0852 - val_accuracy: 0.8394\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.8540\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1135 - val_accuracy: 0.8467\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1227 - val_accuracy: 0.8394\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1341 - val_accuracy: 0.8394\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.8467\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1525 - val_accuracy: 0.8321\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1671 - val_accuracy: 0.8467\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1720 - val_accuracy: 0.8394\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1844 - val_accuracy: 0.8467\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1865 - val_accuracy: 0.8394\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1989 - val_accuracy: 0.8394\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2176 - val_accuracy: 0.8467\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2179 - val_accuracy: 0.8394\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2280 - val_accuracy: 0.8394\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2372 - val_accuracy: 0.8394\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2499 - val_accuracy: 0.8467\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2604 - val_accuracy: 0.8394\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2686 - val_accuracy: 0.8321\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2815 - val_accuracy: 0.8394\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2881 - val_accuracy: 0.8540\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.2935 - val_accuracy: 0.8467\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.8467\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3164 - val_accuracy: 0.8467\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3315 - val_accuracy: 0.8467\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3281 - val_accuracy: 0.8467\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3437 - val_accuracy: 0.8467\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3617 - val_accuracy: 0.8467\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3692 - val_accuracy: 0.8467\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3865 - val_accuracy: 0.8613\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3809 - val_accuracy: 0.8467\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3958 - val_accuracy: 0.8467\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3989 - val_accuracy: 0.8467\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4059 - val_accuracy: 0.8467\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4211 - val_accuracy: 0.8467\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4319 - val_accuracy: 0.8467\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4429 - val_accuracy: 0.8540\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4391 - val_accuracy: 0.8394\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4663 - val_accuracy: 0.8540\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4665 - val_accuracy: 0.8394\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4747 - val_accuracy: 0.8467\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4833 - val_accuracy: 0.8467\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4901 - val_accuracy: 0.8394\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5031 - val_accuracy: 0.8394\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5084 - val_accuracy: 0.8467\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5116 - val_accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11735fd71c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train,y_train,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "rounded = [round(x[0]) for x in y_pred_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train1 = pd.DataFrame(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "408  0\n",
       "409  1\n",
       "410  0\n",
       "411  1\n",
       "412  1\n",
       "\n",
       "[413 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "rounded1    = [round(x[0]) for x in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "99   0\n",
       "100  1\n",
       "101  1\n",
       "102  1\n",
       "103  0\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test1 = pd.DataFrame(rounded1)\n",
    "y_pred_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01188281923532486, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Train = model.evaluate(X_train,y_pred_train1,verbose=0)\n",
    "Accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.019988011568784714, 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Test = model.evaluate(X_test,y_pred_test1,verbose=0)\n",
    "Accuracy_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 14ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 8.3475e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.0861e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 5.2513e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.6798e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.1320e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.8664e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 3.6334e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.4716e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.3450e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.2203e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1094e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.9986e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.9256e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.8365e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.7703e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.6900e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.6212e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5641e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.5054e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 2.4516e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.3914e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3461e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3034e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2527e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2236e-04 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.1731e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.1430e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0966e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0593e-04 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0258e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.9904e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.9579e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.9325e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9063e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8692e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8413e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8140e-04 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.7943e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.7646e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.7383e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7029e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6664e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6471e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6275e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.6039e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.5850e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.5640e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5459e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5250e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5141e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4897e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.4783e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4605e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4436e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4276e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.4075e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 1.3959e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.3793e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 1.3646e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.3525e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.3348e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3196e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3065e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.2949e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2802e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2705e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2549e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2433e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2322e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2185e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.2085e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 1.1958e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.1853e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1625e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1532e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1337e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1244e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1121e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1023e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0941e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0853e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0746e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0657e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0558e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0464e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0377e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.0304e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0229e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0127e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0040e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 9.9710e-05 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.8911e-05 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.8020e-05 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9.7165e-05 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9.6543e-05 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 9.5926e-05 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9.5045e-05 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9.4252e-05 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9.3653e-05 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 9.2870e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 9.2140e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 9.1441e-05 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 9.0874e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9.0236e-05 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.9588e-05 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 8.8909e-05 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 8.8179e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 8.7448e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 8.7088e-05 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 8.6329e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 8.5610e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 8.5215e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9714\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.4421e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9714\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 8.3955e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9714\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 8.3189e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9714\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 8.2887e-05 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9714\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 8.2278e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9714\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 8.1574e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9714\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 8.1054e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9714\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 8.0558e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9714\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.9922e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9714\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.9324e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9714\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 7.8805e-05 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9714\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 7.8295e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9714\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 7.7932e-05 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9714\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 7.7288e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9714\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 7.6752e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9714\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 7.6351e-05 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9714\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 7.5713e-05 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9714\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 7.5299e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9714\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.4811e-05 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9714\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 7.4216e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9714\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 7.3898e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9714\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 7.3395e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9714\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.2937e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9714\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.2512e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9714\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.1980e-05 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9714\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.1503e-05 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9714\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7.1127e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9714\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 7.0642e-05 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9714\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.0249e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9714\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.0047e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9714\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.9420e-05 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(X_test,y_pred_test1,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history \n",
    "# list all data in history\n",
    "\n",
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameters : Batch Size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimizers\n",
      "  Downloading Optimizers-v2.1.tar.gz (1.6 kB)\n",
      "Collecting requests>=2.24.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2.8)\n",
      "Building wheels for collected packages: optimizers\n",
      "  Building wheel for optimizers (setup.py): started\n",
      "  Building wheel for optimizers (setup.py): finished with status 'done'\n",
      "  Created wheel for optimizers: filename=Optimizers-2.1-py3-none-any.whl size=2284 sha256=4a43e3b089ee7751872e24f62a8c0e81ae82c28cbf67614a9d502c02457ac8d1\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\56\\a5\\4d\\f679a391b5fca0b18c5e2fcd66ebff8900d97d6d95713915b9\n",
      "Successfully built optimizers\n",
      "Installing collected packages: charset-normalizer, requests, optimizers\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "Successfully installed charset-normalizer-2.0.6 optimizers-2.1 requests-2.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(30, input_dim=28, activation='relu'))\n",
    "    model1.add(Dense(28, activation='relu'))\n",
    "    model1.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "   \n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.942, total=   1.5s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.750, total=   1.6s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.621, total=   1.6s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.680, total=   1.5s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.728, total=   1.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.990, total=   3.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.846, total=   3.8s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   15.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.786, total=   4.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   19.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.854, total=   4.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   23.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.845, total=   4.0s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=1.000, total=   6.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.837, total=   7.2s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.845, total=   6.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.845, total=   6.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.835, total=   6.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.913, total=   1.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.750, total=   1.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.553, total=   1.6s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.689, total=   1.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.728, total=   1.3s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.942, total=   3.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.779, total=   2.7s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.757, total=   2.8s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.835, total=   3.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.883, total=   2.8s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.981, total=   3.9s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.798, total=   4.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.854, total=   4.5s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.825, total=   4.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.874, total=   4.0s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.990, total=   1.2s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.750, total=   1.2s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.563, total=   1.1s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.680, total=   1.2s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.709, total=   1.4s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.923, total=   1.7s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.779, total=   1.8s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.699, total=   1.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.757, total=   1.6s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.806, total=   2.1s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.942, total=   2.7s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.779, total=   2.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.825, total=   2.8s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.806, total=   2.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.825, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model2 = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model2,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8721620678901673, using {'batch_size': 10, 'epochs': 100}\n",
      "0.7442867755889893,0.10844280768399954 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.8643950819969177,0.0674953630732254 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.8721620678901673,0.06404515982439624 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7268670678138733,0.11563351113746635 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.8393764019012451,0.06777075568210428 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.8664488315582275,0.0626762747803529 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7383681774139405,0.14049515570289045 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7928117990493775,0.07401483310299616 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.8354928970336915,0.05605098103430018 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From summary we can say best result ,when batch-size = 10 and epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameter :Number of neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model1(neuron1,neuron2):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(neuron1,input_dim = 28,activation = 'relu'))\n",
    "    model3.add(Dense(neuron2,activation = 'relu'))\n",
    "    model3.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model3.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] neuron1=24, neuron2=20 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=20, score=0.971, total=   2.4s\n",
      "[CV] neuron1=24, neuron2=20 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=20, score=0.750, total=   1.7s\n",
      "[CV] neuron1=24, neuron2=20 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=20, score=0.583, total=   1.4s\n",
      "[CV] neuron1=24, neuron2=20 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=20, score=0.680, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=20 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=20, score=0.709, total=   1.2s\n",
      "[CV] neuron1=24, neuron2=24 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=24, score=0.981, total=   1.2s\n",
      "[CV] neuron1=24, neuron2=24 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=24, score=0.750, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=24 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   10.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=24, score=0.524, total=   1.2s\n",
      "[CV] neuron1=24, neuron2=24 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=24, score=0.660, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=24 ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. neuron1=24, neuron2=24, score=0.699, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=24, neuron2=28, score=0.981, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=24, neuron2=28, score=0.750, total=   1.1s\n",
      "[CV] neuron1=24, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=24, neuron2=28, score=0.534, total=   1.2s\n",
      "[CV] neuron1=24, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=24, neuron2=28, score=0.689, total=   1.2s\n",
      "[CV] neuron1=24, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=24, neuron2=28, score=0.699, total=   1.1s\n",
      "[CV] neuron1=28, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=20, score=0.971, total=   1.1s\n",
      "[CV] neuron1=28, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=20, score=0.750, total=   1.1s\n",
      "[CV] neuron1=28, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=20, score=0.553, total=   1.1s\n",
      "[CV] neuron1=28, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=20, score=0.689, total=   1.2s\n",
      "[CV] neuron1=28, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=20, score=0.728, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=24, score=1.000, total=   2.3s\n",
      "[CV] neuron1=28, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=24, score=0.760, total=   1.4s\n",
      "[CV] neuron1=28, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=24, score=0.534, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=24, score=0.680, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=24, score=0.728, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=28, score=0.990, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=28, score=0.750, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=28, score=0.553, total=   1.3s\n",
      "[CV] neuron1=28, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=28, score=0.689, total=   1.4s\n",
      "[CV] neuron1=28, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=28, neuron2=28, score=0.709, total=   1.5s\n",
      "[CV] neuron1=35, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=20, score=0.952, total=   1.7s\n",
      "[CV] neuron1=35, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=20, score=0.750, total=   1.2s\n",
      "[CV] neuron1=35, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=20, score=0.544, total=   1.7s\n",
      "[CV] neuron1=35, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=20, score=0.680, total=   1.3s\n",
      "[CV] neuron1=35, neuron2=20 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=20, score=0.699, total=   1.5s\n",
      "[CV] neuron1=35, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=24, score=0.971, total=   1.4s\n",
      "[CV] neuron1=35, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=24, score=0.740, total=   1.3s\n",
      "[CV] neuron1=35, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=24, score=0.534, total=   1.3s\n",
      "[CV] neuron1=35, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=24, score=0.680, total=   1.2s\n",
      "[CV] neuron1=35, neuron2=24 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=24, score=0.699, total=   1.5s\n",
      "[CV] neuron1=35, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=28, score=0.971, total=   2.2s\n",
      "[CV] neuron1=35, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=28, score=0.750, total=   1.8s\n",
      "[CV] neuron1=35, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=28, score=0.583, total=   1.4s\n",
      "[CV] neuron1=35, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=28, score=0.680, total=   1.1s\n",
      "[CV] neuron1=35, neuron2=28 ..........................................\n",
      "[CV] .............. neuron1=35, neuron2=28, score=0.689, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model4 = KerasClassifier(build_fn = create_model1,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [24,28,35]\n",
    "neuron2 = [20,24,28]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid2        = GridSearchCV(estimator = model4,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result2 = grid2.fit(x_scaled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.740272581577301, using {'neuron1': 28, 'neuron2': 24}\n",
      "0.7384055256843567,0.12879601496304818 with: {'neuron1': 24, 'neuron2': 20}\n",
      "0.7228528738021851,0.1491213705393393 with: {'neuron1': 24, 'neuron2': 24}\n",
      "0.7306198716163635,0.14444438776186963 with: {'neuron1': 24, 'neuron2': 28}\n",
      "0.7384055256843567,0.13494324158624202 with: {'neuron1': 28, 'neuron2': 20}\n",
      "0.740272581577301,0.1511392956202306 with: {'neuron1': 28, 'neuron2': 24}\n",
      "0.7383681893348694,0.142228814012503 with: {'neuron1': 28, 'neuron2': 28}\n",
      "0.7248506307601928,0.13245914481515295 with: {'neuron1': 35, 'neuron2': 20}\n",
      "0.7248319745063782,0.1414576010419955 with: {'neuron1': 35, 'neuron2': 24}\n",
      "0.734522032737732,0.129919852052271 with: {'neuron1': 35, 'neuron2': 28}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result2.best_score_,grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  From summary best result at 1st layer 28 Neuron and 2nd layer 24 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameter : Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model2(activation_function):\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(28,input_dim = 28,activation = activation_function))\n",
    "    model4.add(Dense(24,activation = activation_function))\n",
    "    model4.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model4.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] activation_function=softmax .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... activation_function=softmax, score=1.000, total=   1.7s\n",
      "[CV] activation_function=softmax .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... activation_function=softmax, score=0.750, total=   1.5s\n",
      "[CV] activation_function=softmax .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... activation_function=softmax, score=0.524, total=   1.4s\n",
      "[CV] activation_function=softmax .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... activation_function=softmax, score=0.680, total=   1.8s\n",
      "[CV] activation_function=softmax .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... activation_function=softmax, score=0.699, total=   1.4s\n",
      "[CV] activation_function=relu ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ activation_function=relu, score=0.942, total=   1.4s\n",
      "[CV] activation_function=relu ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    9.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ activation_function=relu, score=0.740, total=   1.2s\n",
      "[CV] activation_function=relu ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   10.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ activation_function=relu, score=0.534, total=   1.1s\n",
      "[CV] activation_function=relu ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   11.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ activation_function=relu, score=0.680, total=   1.4s\n",
      "[CV] activation_function=relu ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ activation_function=relu, score=0.699, total=   1.3s\n",
      "[CV] activation_function=tanh ........................................\n",
      "[CV] ............ activation_function=tanh, score=0.942, total=   1.3s\n",
      "[CV] activation_function=tanh ........................................\n",
      "[CV] ............ activation_function=tanh, score=0.740, total=   1.5s\n",
      "[CV] activation_function=tanh ........................................\n",
      "[CV] ............ activation_function=tanh, score=0.612, total=   1.6s\n",
      "[CV] activation_function=tanh ........................................\n",
      "[CV] ............ activation_function=tanh, score=0.689, total=   1.6s\n",
      "[CV] activation_function=tanh ........................................\n",
      "[CV] ............ activation_function=tanh, score=0.728, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   22.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model5 = KerasClassifier(build_fn = create_model2,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(activation_function=activation_function)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid3        = GridSearchCV(estimator = model5,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result3 = grid3.fit(x_scaled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.742363703250885, using {'activation_function': 'tanh'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax'}\n",
      "0.7190627455711365,0.1315340802157195 with: {'activation_function': 'relu'}\n",
      "0.742363703250885,0.10962020325271954 with: {'activation_function': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result3.best_score_,grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From summary best result when Activation function is 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
